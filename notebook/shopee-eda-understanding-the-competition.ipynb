{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Introduction and Imports ðŸ“”\n","\n","Let's get started with this new image competition! \n","Below is a brief introduction to it as well as the data files present here!\n","\n","* Edit:\n","I recently wrote a notebook where I am <strong style=\"color:'green'\"><a href=\"https://www.kaggle.com/heyytanay/finding-similar-images-using-image-deduplicator\">Finding Similar Products using Image De-duplicator ðŸ“¸</a></strong>, you can check it out to see a possible Image based solution to this challenge."]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import os\n","import cv2\n","import glob\n","import random\n","\n","from rich import print as _pprint"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["def cprint(string):\n","    \"\"\"\n","    Utility function for beautiful colored printing.\n","    \"\"\"\n","    _pprint(f\"[black]{string}[/black]\")"]},{"cell_type":"markdown","metadata":{},"source":["## What is our task? ðŸŽ¯\n","\n","Ok, so in this competition we are provided with images of different products posted by users on the platform, **Shopee** and our task is to identify if two (or more) posted products are same.\n","\n","During inference, we will be provided with `posting_id`, image name (`image`), `image_phash` (perceptual hash of the image) and the `title` of the image.\n","And out task will be to find **at-most 49 matching images** to the one currently in question.\n","\n","This is a Code-Competition and hence only 3 samples are currently in the test set but the model will be evaluated on more samples (about *70K images*) privately when submitted.\n","The submission file should consist of 2 rows:\n","* `posting_id`: The Posting Id of the image (taken from the test file)\n","* `matches`: All the different matches to the current image by their posting id. Keep in mind, all images are a self match for first (i.e: all images also match themselves, so you would have to include that in your entry too). Different posting ids will be separated by space."]},{"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"cell_type":"markdown","metadata":{},"source":["## How does the Data look like? ðŸ—ƒ\n","\n","So, the data provided to us in this competition consists of 3 `.csv` files and 2 folders (`training_images` and `testing_images`).\n","\n","Below is the breakdown of the `.csv` files and image folders;\n","\n","* ðŸ“„ `train.csv` - This is the Training set metadata. Each row contains the data for a single posting. Multiple postings might have the exact same image ID, but with different titles or vice versa.\n","\n","\n","* ðŸ“„ `test.csv` - Same as `train.csv` except the `label_group` column. This file will be what we are going to use at inference time. Currently it only consists of 3 samples but it will be replaced by a bigger private test set at submission time.\n","\n","\n","* ðŸ“„ `sample_submission.csv` - The Sample submission file in the format we are expected to follow.\n","\n","\n","* ðŸ“‚ `train_images/` - Folder with all the training images.\n","\n","\n","* ðŸ“‚ `test_images/` - Folder with all the testing images (again, only 4 images for now, but will be around ~70,000 images during submission)"]},{"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"cell_type":"markdown","metadata":{},"source":["## Evaluation Metric âœ’\n","\n","In this competition, our submissions will be judged on F1 Score metric.\n","\n","The F1 score can be interpreted as a weighted average of the precision and recall, where an F1 score reaches its best value at 1 and worst score at 0. \n","\n","The relative contribution of precision and recall to the F1 score are equal.\n","\n","$$F1 = \\frac{2 \\cdot precision\\cdot recall}{precision+ recall}$$\n","\n","where,\n","\n","$$precision=\\frac{True Positive}{True Positive + False Positive}$$\n","<br>\n","$$recall=\\frac{True Positive}{True Positive + False Negative}$$"]},{"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"cell_type":"markdown","metadata":{},"source":["## Peeking at the Data ðŸ“ˆ\n","\n","Now that you have an understanding of the task and the dataset, let's start by looking at the different data files provided and some stats!"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["train_file = pd.read_csv(\"../input/shopee-product-matching/train.csv\")\n","train_file.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["test_file = pd.read_csv(\"../input/shopee-product-matching/test.csv\")\n","test_file.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sample_sub = pd.read_csv(\"../input/shopee-product-matching/sample_submission.csv\")\n","sample_sub.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["total_train_files = glob.glob(\"../input/shopee-product-matching/train_images/*.jpg\")\n","total_test_files = glob.glob(\"../input/shopee-product-matching/test_images/*.jpg\")\n","\n","cprint(f\"[green]Total Training Images: {len(total_train_files)}[/green]\")\n","cprint(f\"[red]Total Testing Images: {len(total_test_files)}[/red]\")"]},{"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"cell_type":"markdown","metadata":{},"source":["# Image EDA ðŸ“¸\n","\n","Now, let's move to the EDA part and get started by looking at images randomly from the dataset and from different groups."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["def plot(num):\n","    IMG_PATHS = \"../input/shopee-product-matching/train_images/\"\n","    sq_num = np.sqrt(num)\n","    assert sq_num == int(sq_num), \"Number of Images must be a perfect Square!\"\n","\n","    sq_num = int(sq_num)\n","    image_ids = os.listdir(IMG_PATHS)\n","    random.shuffle(image_ids)\n","    fig, ax = plt.subplots(nrows=sq_num, ncols=sq_num, figsize=(10, 10))\n","\n","    for i in range(sq_num):\n","        for j in range(sq_num):\n","            idx = i*sq_num + j\n","            ax[i, j].axis('off')\n","            img = cv2.imread(IMG_PATHS + '/' + image_ids[idx])\n","            img = img[:, :, ::-1]\n","            ax[i, j].imshow(img); ax[i, j].set_title(f'{image_ids[idx]}', fontsize=6.5)\n","\n","    plt.show()\n","    \n","    \n","def plot_from_label(group):\n","    IMG_PATHS = \"../input/shopee-product-matching/train_images/\"\n","    image_list = train_file[train_file['label_group'] == group]\n","    image_list = image_list['image'].tolist()\n","    num = len(image_list)\n","    \n","    sq_num = np.sqrt(num)\n","\n","    sq_num = int(sq_num)\n","    image_ids = os.listdir(IMG_PATHS)\n","    random.shuffle(image_ids)\n","    fig, ax = plt.subplots(nrows=sq_num, ncols=sq_num, figsize=(10, 10))\n","    \n","    path = [os.path.join(IMG_PATHS, x) for x in image_list]\n","    \n","    for i in range(sq_num):\n","        for j in range(sq_num):\n","            idx = i*sq_num + j\n","            ax[i, j].axis('off')\n","            img = cv2.imread(path[idx])\n","            img = img[:, :, ::-1]\n","            ax[i, j].imshow(img)\n","\n","    plt.show()\n","\n","def plot_from_title(title):\n","    IMG_PATHS = \"../input/shopee-product-matching/train_images/\"\n","    image_list = train_file[train_file['title'] == title]\n","    image_list = image_list['image'].tolist()\n","    num = len(image_list)\n","    \n","    sq_num = np.sqrt(num)\n","    sq_num = int(sq_num)\n","    \n","    image_ids = os.listdir(IMG_PATHS)\n","    random.shuffle(image_ids)\n","    fig, ax = plt.subplots(nrows=sq_num, ncols=sq_num, figsize=(10, 10))\n","    fig.suptitle(f\"Product Name: {title}\")\n","    path = [os.path.join(IMG_PATHS, x) for x in image_list]\n","    \n","    for i in range(sq_num):\n","        for j in range(sq_num):\n","            idx = i*sq_num + j\n","            ax[i, j].axis('off')\n","            img = cv2.imread(path[idx])\n","            img = img[:, :, ::-1]\n","            ax[i, j].imshow(img)\n","            \n","    plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Plotting Products Naively\n","\n","Let's start Image EDA by plotting the products just randomly from the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Plot 16 random images\n","plot(16)"]},{"cell_type":"markdown","metadata":{},"source":["## Plotting Products based on Image Label Group\n","\n","Let's take a little smarter approach by plotting products based on their label group."]},{"cell_type":"markdown","metadata":{},"source":["**Image Label Group: 1141798720**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_from_label(1141798720)"]},{"cell_type":"markdown","metadata":{},"source":["**Image Label group: 994676122**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_from_label(994676122)"]},{"cell_type":"markdown","metadata":{},"source":["## Product Images with Same Name\n","\n","Now let's see some product images that have same name (title). \n","\n","This will help us see how the images with same title can be different from each other."]},{"cell_type":"markdown","metadata":{},"source":["**Title: Koko syubbanul muslimin koko azzahir koko baju**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_from_title(\"Koko syubbanul muslimin koko azzahir koko baju\")"]},{"cell_type":"markdown","metadata":{},"source":["**Title: Monde Boromon Cookies 1 tahun+ 120gr**"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["plot_from_title(\"Monde Boromon Cookies 1 tahun+ 120gr\")"]},{"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"cell_type":"markdown","metadata":{},"source":["## Top-15 Image Label Groups\n","\n","Let's see the top-15 image label groups (by the number of images) in this dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["sns.set_palette(\"tab20\")\n","top10_names = train_file['label_group'].value_counts().index.tolist()[:15]\n","top10_values = train_file['label_group'].value_counts().tolist()[:15]\n","\n","plt.figure(figsize=(10, 10))\n","sns.barplot(x=top10_names, y=top10_values)\n","plt.xticks(rotation=45)\n","plt.xlabel(\"Label Group\")\n","plt.ylabel(\"Image Count\")\n","plt.title(\"Top-15 Label Groups by Image Count\")\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["## Top-5 Products from Images\n","\n","Let's see the top-5 products (by count of titles) in this dataset using their provided images."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["top5_products = train_file['title'].value_counts()[:5].index.tolist()\n","for title in top5_products:\n","    plot_from_title(title)"]},{"cell_type":"markdown","metadata":{},"source":["<hr>"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-input":true,"trusted":true},"outputs":[],"source":["cprint(\"[bold blue]UNDER WORK! MORE STUFF IS IN THE PROCESS OF BEING ADDED.[/bold blue]\")"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.12"}},"nbformat":4,"nbformat_minor":4}
